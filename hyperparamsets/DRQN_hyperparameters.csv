id ,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41
epsilon,"{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':3,'rate':17,'maxep':1.0,'minep':0.01}","{'type':3,'rate':17,'maxep':1.0,'minep':0.01}","{'type':3,'rate':17,'maxep':1.0,'minep':0.01}","{'type':4,'fix':100000,'a':0.1,'bf':30,'cf':0.4,'minep':0.01}","{'type':6,'val':0.15}","{'type':6,'val':0.15}","{'type':6,'val':0.15}","{'type':6,'val':0.15}","{'type':6,'val':0.15}","{'type':6,'val':0.15}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.1}","{'type':6,'val':0.2}","{'type':6,'val':0.2}","{'type':6,'val':0.1}","{'type':6,'val':0.2}"
lr,0.01,0.01,0.001,0.001,0.01,0.0005,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
lrdecaytype,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp,exp
lrdecay,0.9992,0.9992,0.9992,0.9992,0.9992,0.99999,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992,0.9992
minlr,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf,inf
training_cycle,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7
target_update_cycle,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15
ddqn,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
nstep,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
distributional,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
atomn,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,0
vmin,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,-104,0
vmax,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,1002,0
memory size,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000
batch size,100,100,100,100,100,100,100,100,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,40,25,25,25,25,25,100
seql,1,1,1,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,1
min_seql,1,1,1,1,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1
burninl,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
postterm_len,3,3,3,3,3,3,3,3,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,3
hidden_num,2,2,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,3,3,3
hidden_size,30,30,30,20,20,8,8,8,10,10,10,10,10,10,10,10,14,14,14,14,14,14,14,14,20,20,20,20,20,20,20,20,30,30,40,40,60,40,40,30,30,30
lstm_num,30,30,30,20,20,16,16,16,16,16,16,16,16,24,24,24,34,34,34,30,30,30,30,30,36,36,36,36,46,46,60,20,25,25,30,30,50,30,30,30,30,5
lstm_layers,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
max_steps,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100
episodenum,10000,10000,10000,1000,6000,6000,6000,6000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,2000,1000,5000,5000,5000,5000,5000,5000,5000,5000,300,5000
external testing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
normalize,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
bestQinit,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
actioninput,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
samplefromstart,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
performance_sampleN,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,1000,1000,1000,1000,1000,1000,1000,100
final_performance_sampleN,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,1000,1000,1000,1000,1000,1000,1000,100
evaluation_interval,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100
envid,Env2.1,Env2.1,Env2.1,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,tiger,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1,Env2.1
envconfig,"{'initstate':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}",{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},{'init':[-1]},"{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}","{'init':[-1,-1,-1,-1,-1,-1],'paramset':2,'discretization':0}"
seed,799,random,random,12,12,12,12,12,12,856,938,851,509,979,670,505,295,random,178,543,549,964,90379,62850,18202,5389,96637,37394,74972,6976,78921;69919;96951;12463;96540;35267;70795;41032;38728;60512;88891;34573,random,random,random,random,random,random,random,random,random,11111,random
notes,for env1.0 single sequence. Sanity check,for env1.0 single sequence. Sanity check,for env1.0 single sequence. Sanity check,tiger Pomdp,tiger Pomdp,tiger Pomdp,tiger Pomdp,tiger Pomdp FOR RQNN2,tiger Pomdp,for fully observable tiger. It works! But training very unstable.,works on 0.02 0.98 observation probability,works on 0.02 0.98 observation probability,0.02 and 0.98 default. 0.0 1.0 survey. Keep surveying every time absent,"0.02 and 0.98 default. 0.0 1.0 survey. Larger lstm width than 12, now doesn't survey and remember last presence when absence and manages!",0.05 and 0.95 default. 0.0 1.0 survey,0.1 and 0.9 default. 0.0 1.0 survey,0.15 and 0.85 default. 0.0 1.0 survey. Works well but doesn't survey,0.2 and 0.8 default. 0.0 1.0 survey. Doesn't work well,0.2 and 0.8 default. 0.0 1.0 survey. With previous action input. Doesn't workwell,0.2 and 0.8 default. 0.0 1.0 survey. Works well. 1300th episode network uses survey too!,0.3 and 0.7 default. 0.0 1.0.works and has surveying at 900th ep,0.4 and 0.6 default. 0.0 1.0. works,0.5 and 0.5 default. 0.0 1.0. works with survey,0.6 and 0.4 default. 0.0 1.0. works and has surveying,0.7 and 0.3 default. 0.0 1.0. works with surveying,0.8 and 0.2 default. 0.0 1.0. works with surveying,"0.9 and 0.1 default. 0.0 1.0. kind of works, doesn't use surveying",0.9 and 0.1 default. 0.0 1.0. works well with surveying. Also works with seed num 93161,"0.9 and 0.1 default. 0.0 1.0. works well with surveying. Also works with seed num 70110,26655,8400,39004",0.99 and 0.01 default. 0.0 1.0. works with surveying but only manages one time after presence with surveying,0.99 and 0.01 default. 0.0 1.0. works with surveying. Increasing the lstm width made finding good policy easier. Seednumbers onlywork in discovery HPC. This marks the end of Tiger pomdp exercise!,for env2.1. didn't work well,for env2.1. found one! Seed might only work on discovery hpc.,for env2.1. 2 hidden layer +lstm. Not very good. Two 4000's.,for env2.1. 1 layer hidden more cells per layer. Finds few 4000's. need above 4300 now.,for env2.1. increased batch size to 40 from param34. not very successful.,for env2.1. increased layerwidth from param34. didn't work well. I think its overkill,"for env2.1. epsilon constant value 0.1, everything else is 34",for env2.1. DDQN with param 34,"for env2.1. DDQN, 3 hidden layer ",dummy set for hyperparameter setting,for env2.1. decreasing lstm layer width to 5 and increasing FF layer number to 3. Also changing sequence length to 1 
score,0,0,0,0,1800,1000,,1000,,2618,2663,2663,2600,2700,2700,2600,2600,2600,2600,2600,2500,2600,2300,2500,2500,2500,2200,2400,2400,2214,2500,3000,4300,4000,,,,,4000,,,
